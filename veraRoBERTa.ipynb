{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13462dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer,get_linear_schedule_with_warmup,RobertaTokenizer,BertForSequenceClassification,BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import get_peft_model\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e004ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Percentage of trainable params: {100 * trainable / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a80d5",
   "metadata": {},
   "source": [
    "## Custom RoBERTa class needs work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b8a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "class RobertaForSequenceClassificationWithCustomHead(RobertaForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # Add a new custom layer, e.g., a small MLP after the original classifier\n",
    "        self.custom_layer = nn.Sequential(\n",
    "            nn.Linear(config.num_labels, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, config.num_labels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "\n",
    "        # Remove any unexpected keys that RobertaForSequenceClassification won't accept\n",
    "        accepted_keys = {\"input_ids\", \"attention_mask\", \"labels\", \"token_type_ids\", \"position_ids\", \"head_mask\", \"inputs_embeds\", \"output_attentions\", \"output_hidden_states\", \"return_dict\"}\n",
    "        filtered_kwargs = {k: v for k, v in kwargs.items() if k in accepted_keys}\n",
    "\n",
    "        # Safe call to parent forward\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            **filtered_kwargs\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        custom_logits = self.custom_layer(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(custom_logits, labels)\n",
    "\n",
    "        return type(outputs)(\n",
    "            loss=loss,\n",
    "            logits=custom_logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23b9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeRALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=1, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features), requires_grad=False)\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "\n",
    "        self.u = nn.Parameter(torch.randn(rank, out_features))\n",
    "        self.v = nn.Parameter(torch.randn(rank, in_features))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        delta_w = torch.matmul(self.u.T, self.v)\n",
    "        w_eff = self.weight + delta_w\n",
    "        return F.linear(x, w_eff, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97801682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_VeRA_to_roberta(model, rank=1):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            in_f, out_f = module.in_features, module.out_features\n",
    "            vera_layer = VeRALinear(in_f, out_f, rank=rank, bias=(module.bias is not None))\n",
    "            vera_layer.weight.data.copy_(module.weight.data)\n",
    "            if module.bias is not None:\n",
    "                vera_layer.bias.data.copy_(module.bias.data)\n",
    "\n",
    "            parent = model\n",
    "            path = name.split(\".\")\n",
    "            for part in path[:-1]:\n",
    "                parent = getattr(parent, part)\n",
    "            setattr(parent, path[-1], vera_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4f4d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassificationWithCustomHead were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'custom_layer.0.bias', 'custom_layer.0.weight', 'custom_layer.2.bias', 'custom_layer.2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.53.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Trainable parameters: 39,794,706\n",
      "Total parameters: 125,332,626\n",
      "Percentage of trainable params: 31.75%\n",
      "Number of available GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "model = RobertaForSequenceClassificationWithCustomHead.from_pretrained(\"roberta-base\", num_labels=15)\n",
    "model = apply_VeRA_to_roberta(model, rank=4)\n",
    "print(model.config)\n",
    "print_trainable_parameters(model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "device\n",
    "\n",
    "# Pretrained RoBERTa tokenizer (e.g. roberta-base)\n",
    "#pretrained_tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Your custom tokenizer trained on OOL tokens\n",
    "custom_tokenizer = RobertaTokenizer.from_pretrained('./tokenizer') # Try to remove Fast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ab2c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30522 new tokens to use.\n"
     ]
    }
   ],
   "source": [
    "custom_vocab = set(custom_tokenizer.get_vocab().keys())\n",
    "\n",
    "new_tokens = list(custom_vocab)\n",
    "\n",
    "print(f\"Found {len(new_tokens)} new tokens to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177c29cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(custom_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed77f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VeraConfig.__init__() got an unexpected keyword argument 'lora_alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_peft_model, VeraConfig, TaskType\n\u001b[1;32m----> 3\u001b[0m config \u001b[38;5;241m=\u001b[39m VeraConfig(\n\u001b[0;32m      4\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mSEQ_CLS,     \u001b[38;5;66;03m# or SEQ_2_SEQ_LM, TOKEN_CLS, etc.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      6\u001b[0m     lora_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m      7\u001b[0m     lora_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m      8\u001b[0m     target_modules\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m],  \u001b[38;5;66;03m# Adjust for RoBERTa,\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m get_peft_model(model, config)\n\u001b[0;32m     13\u001b[0m print_trainable_parameters(model)\n",
      "\u001b[1;31mTypeError\u001b[0m: VeraConfig.__init__() got an unexpected keyword argument 'lora_alpha'"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, VeraConfig, TaskType\n",
    "\n",
    "config = VeraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,     # or SEQ_2_SEQ_LM, TOKEN_CLS, etc.\n",
    "    r=4,\n",
    "    vera_dropout=0.1,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  # Adjust for RoBERTa,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c03425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_pickle('./saved_data/encoded_data.pck')\n",
    "le = LabelEncoder()\n",
    "data['target'] = le.fit_transform(data['Attack_type'])\n",
    "\n",
    "data = pd.read_csv(\".\\data\\Edge-IIoTset dataset\\Selected dataset for ML and DL\\ML-EdgeIIoT-dataset.csv\")\n",
    "columns = list(data.columns[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b43492",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"column_name_encoded_data.txt\",\"w\") as f:\n",
    "    for _, row in data.iterrows():\n",
    "        tokens = row.split(\" \")\n",
    "        formatted = []\n",
    "        for idx, (col, tok) in enumerate(zip(columns, tokens)):\n",
    "            end_char = \".\" if idx == len(tokens) - 1 else \";\"\n",
    "            formatted.append(f\"{col}: {tok}{end_char}\")\n",
    "        f.write(formatted)\n",
    "#'<s>','<pad>','</s>','<unk>','<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2841cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_PPFLE_prompt</th>\n",
       "      <th>Attack_type</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85834</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Backdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13069</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Ransomware</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108098</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59604</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Password</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88256</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Backdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47250</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94950</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>XSS</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138385</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_UDP</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110037</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46888</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>SQL_injection</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100674</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>XSS</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27775</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>SQL_injection</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124867</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73218</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Port_Scanning</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     encoded_PPFLE_prompt    Attack_type  \\\n",
       "85834   You are an expert in network traffic classific...       Backdoor   \n",
       "13069   You are an expert in network traffic classific...     Ransomware   \n",
       "108098  You are an expert in network traffic classific...         Normal   \n",
       "59604   You are an expert in network traffic classific...       Password   \n",
       "88256   You are an expert in network traffic classific...       Backdoor   \n",
       "47250   You are an expert in network traffic classific...       DDoS_TCP   \n",
       "94950   You are an expert in network traffic classific...            XSS   \n",
       "138385  You are an expert in network traffic classific...       DDoS_UDP   \n",
       "110037  You are an expert in network traffic classific...         Normal   \n",
       "46888   You are an expert in network traffic classific...       DDoS_TCP   \n",
       "24994   You are an expert in network traffic classific...  SQL_injection   \n",
       "100674  You are an expert in network traffic classific...            XSS   \n",
       "27775   You are an expert in network traffic classific...  SQL_injection   \n",
       "124867  You are an expert in network traffic classific...         Normal   \n",
       "73218   You are an expert in network traffic classific...  Port_Scanning   \n",
       "\n",
       "        Attack_label  target  \n",
       "85834              1       0  \n",
       "13069              1      10  \n",
       "108098             0       7  \n",
       "59604              1       8  \n",
       "88256              1       0  \n",
       "47250              1       3  \n",
       "94950              1      14  \n",
       "138385             1       4  \n",
       "110037             0       7  \n",
       "46888              1       3  \n",
       "24994              1      11  \n",
       "100674             1      14  \n",
       "27775              1      11  \n",
       "124867             0       7  \n",
       "73218              1       9  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"column_name_encoded_data.txt\", \"r\") as f:\n",
    "    prompt_lines = f.readlines()\n",
    "\n",
    "# Strip newline characters\n",
    "prompt_lines = [prompt_line.strip() for prompt_line in prompt_lines]\n",
    "prompt_data = {\n",
    "    \"encoded_PPFLE_prompt\": prompt_lines, 'Attack_type': data['Attack_type'], 'Attack_label': data['Attack_label'], 'target': data['target']\n",
    "}\n",
    "prompt_df = pd.DataFrame(prompt_data)\n",
    "prompt_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccdbe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110460, 4) (23670, 4) (23670, 4)\n"
     ]
    }
   ],
   "source": [
    "train_set = prompt_df.sample(frac=0.7,random_state=42).reset_index(drop=True)\n",
    "\n",
    "remaining = prompt_df.drop(train_set.index).reset_index(drop=True)\n",
    "\n",
    "test_set = remaining.sample(frac=0.5,random_state=42).reset_index(drop=True)\n",
    "\n",
    "val_set = remaining.drop(test_set.index).reset_index(drop=True)\n",
    "\n",
    "print(train_set.shape,val_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a459bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_set, test_set = train_test_split(prompt_df, test_size=test_ratio,stratify=prompt_df.iloc[:,-1], random_state=42)\n",
    "train_set, val_set = train_test_split(train_set, test_size=val_ratio/(val_ratio+train_ratio),stratify=train_set.iloc[:,-1], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07865133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110460, 4), (23670, 4), (23670, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape,val_set.shape,test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184962cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LIST = ['Backdoor', 'DDoS_HTTP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_UDP',\n",
    "                'Fingerprinting', 'MITM', 'Normal', 'Password', 'Port_Scanning',\n",
    "                'Ransomware', 'SQL_injection', 'Uploading', 'Vulnerability_scanner',\n",
    "                'XSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fc530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_PPFLE_prompt</th>\n",
       "      <th>Attack_type</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13140</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13141</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13142</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    encoded_PPFLE_prompt Attack_type  \\\n",
       "13140  You are an expert in network traffic classific...   Uploading   \n",
       "13141  You are an expert in network traffic classific...   Uploading   \n",
       "13142  You are an expert in network traffic classific...   Uploading   \n",
       "13143  You are an expert in network traffic classific...   Uploading   \n",
       "13144  You are an expert in network traffic classific...   Uploading   \n",
       "\n",
       "       Attack_label  target  \n",
       "13140             1      12  \n",
       "13141             1      12  \n",
       "13142             1      12  \n",
       "13143             1      12  \n",
       "13144             1      12  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_df[prompt_df['Attack_type']=='Uploading'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b0006",
   "metadata": {},
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self,encodings,df,max_len):\n",
    "    self.encodings = encodings\n",
    "    self.df = df\n",
    "    self.max_len=max_len\n",
    "    self.targets = self.df['target'].tolist()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    target = self.targets[idx]\n",
    "    encoding = self.encodings[idx]\n",
    "\n",
    "    return {\n",
    "        'input_ids':encoding['input_ids'].flatten(),\n",
    "        'attention_mask':encoding['attention_mask'].flatten(),\n",
    "        'targets':torch.tensor(target,dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import RobertaTokenizerFast\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and dataset\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_function(row):\n",
    "    return tokenizer(\n",
    "        row[\"encoded_PPFLE_prompt\"],               # replace with your actual column\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize entire dataset\n",
    "train_set_enc = (Dataset.from_pandas(train_set)).map(tokenize_function, batched=True)\n",
    "val_set_enc = (Dataset.from_pandas(val_set)).map(tokenize_function, batched=True)\n",
    "test_set_enc = (Dataset.from_pandas(test_set)).map(tokenize_function, batched=True)\n",
    "\n",
    "# Save to disk (recommended)\n",
    "train_set_enc.save_to_disk('vera_prompt_roberta_train_encodings.pt')\n",
    "val_set_enc.save_to_disk('vera_prompt_roberta_val_encodings.pt')\n",
    "test_set_enc.save_to_disk('vera_prompt_roberta_test_encodings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c34ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110460\n",
      "23670\n",
      "23670\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "train_set_enc = load_from_disk('vera_prompt_roberta_train_encodings.pt')\n",
    "print(len(train_set_enc))\n",
    "val_set_enc = load_from_disk('vera_prompt_roberta_val_encodings.pt')\n",
    "print(len(val_set_enc))\n",
    "test_set_enc = load_from_disk('vera_prompt_roberta_test_encodings.pt')\n",
    "print(len(test_set_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataset_format(dataset):\n",
    "    dataset = dataset.rename_column('target', \"labels\")\n",
    "    dataset.set_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"]  # include \"labels\" column\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = set_dataset_format(train_set_enc)\n",
    "val_dataset = set_dataset_format(val_set_enc)\n",
    "test_dataset = set_dataset_format(test_set_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd4492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n",
      "Labels min, max: (tensor(0), tensor(14))\n",
      "Labels dtype: torch.int64\n",
      "batch.keys = dict_keys(['labels', 'input_ids', 'attention_mask']), \n",
      "tensor([    0,  1185,    32,    41,  3827,    11,  1546,  1703, 20257,     4,\n",
      "         7253,    15,     5,  1286,  1546,  1703, 16763,     6,    47,   531,\n",
      "         3094,   549,     5,  1703,    16,   128, 19085, 11219,  3934,   128,\n",
      "          495, 41501,  1215, 49244,  3934,   128,   495, 41501,  1215,  2371,\n",
      "         7629,  3934,   128,   495, 41501,  1215,  6078,   510,  3934,   128,\n",
      "          495, 41501,  1215,   791,  5174,  3934,   128,   597,  6082, 17265,\n",
      "          154,  3934,   128, 36548,   448,  3934,   128, 45647,  3934,   128,\n",
      "        44917,  3934,   128, 22117,  1215, 42450,  3509,  3934,   128,   500,\n",
      "        32387, 10680,  3934,   128, 46608,  1215,   179, 35892,  3934,   128,\n",
      "        48800,   154,  3934,   128,   846, 45706,  1215, 43511,  1396,  3934,\n",
      "           50,   128,  1000,  8108,  2652,  1398,    32,     5, 45320, 16763,\n",
      "            6,   128, 14210, 31819,  1215,  5756,   597,  3850,    35,  4285,\n",
      "         1225,   506,  2890,  5220,  2517,   506,   306,   417,  6750,   438,\n",
      "        39125,   417, 34248,  2890,  5677,   438, 26868,  1610,  3118, 33845,\n",
      "         1360,   231, 36807,   398,   417,   466, 34836,  3367,   698, 36028,\n",
      "          406,   102,  4111,   438, 40391,   102,  3761, 12010,   288, 19911,\n",
      "          398, 14141,   288, 25484,   401, 34764,   204, 38925,  3367, 32004,\n",
      "        26866, 25484,   288,   438,   466,   625,   428,  1646, 12010,   245,\n",
      "         7904,   401,   506, 32088,  3414,  3103,   417,   246,   242,  9724,\n",
      "         3204,  1749,  5208,  3145, 38504,  2518,  5352, 23219,  5479,   417,\n",
      "          134,   196,   401, 14650,   288, 12010, 30548, 28690,   306,   428,\n",
      "          246,   741,  3367,  1244,   102,  5208, 26866,  1755,  7904,  4563,\n",
      "        40027, 34682,   428, 11893,   246,   428, 40976,   102,  3414,  1922,\n",
      "          242,   306,   290,   417, 37383,   102,   306,   428,  4124,   438,\n",
      "          246, 35470,  4015,   417,   612,  7068,   176,  1942,   245, 19911,\n",
      "        20695,  4671,  4708, 19911,  5208,  6478, 36922,   506, 33845, 35470,\n",
      "         1610, 29221,   428,   398, 36431, 36028,   401,   506,   176,   102,\n",
      "         5243,   417,   406,  1978,  5606,   102, 31276,   242, 37401,   741,\n",
      "         3083,  3367, 32532,   506,  4283, 12010,   245,   102,  4550,   288,\n",
      "        16134,   246,   506,  4280,   428,   306,   242,  3305,   438,  4419,\n",
      "        14141,   506,  4283, 19911,   306,   856,  6750,   417,   466,  3706,\n",
      "         3248,  1922,  2518,  5067,   134,   102,   306,   428,  1570,  4956,\n",
      "          417,  5067,   428,  5339, 36920, 26634,   401,   242,   306,   242,\n",
      "         1366,  7589,  4791,   406,   428,  4015,   438,  4450,  4708, 36028,\n",
      "          612,  5220,   417,   466,   438,   245,  4550,  1549,  4006,   506,\n",
      "         3761,  3416,  1755,   246,   196,   364,   102,  1244,   102,  1225,\n",
      "         3209,   466,   438,  6361,   428,   406,   417,  3083,  1244,  2518,\n",
      "         1866,  5208, 17452,   401, 23219,  6668,  3209,  5379,   428,   856,\n",
      "         4124,   246,   428,   245,   438,  3103, 28503,   102,  3103,  2001,\n",
      "        25423,   176,   438,   288,  7068,  4280,   102,  3414,   438, 39617,\n",
      "         1646,  4550,  4015,   883, 30586,   102,   288,  3178,   398,   102,\n",
      "        30003,   506,   176, 23219,  5677,  1225,  3204,   246,   438,   306,\n",
      "         1610,  3416, 34836,  1646, 29936,   417,   406,   364,   176, 36807,\n",
      "         3118, 36807,  1646,  1043,   417,  3305,  1922,   428,  2001,  7309,\n",
      "        14141,   288,   428,   398,   102, 30042,  3204,   245,   242,   466,\n",
      "         1570,  3209,   155, 33492, 39259,   428, 34490,   102,  6551,   996,\n",
      "         1225,  3714,  3178,  3305,  4718, 34986,  1558,   242,  3416,  3209,\n",
      "          417,   398,  4671,  4268,  2890,   417,   245,   417,   996,  5208,\n",
      "         3272,   242,   698, 28020,   844, 10056,  4671,   428,   246,   242,\n",
      "         1570,  1755, 32976,   417,   406,  3209,  7678, 37413, 38133,   245,\n",
      "          438,   401,  3178,  1558,   102,   288,   196,  3367,  2481,   438,\n",
      "          398,     2])\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=512\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "test_data = next(iter(train_loader))\n",
    "\n",
    "print(test_data['input_ids'].shape)\n",
    "\n",
    "labels = train_dataset[\"labels\"]\n",
    "print(f\"Labels min, max: {labels.min(), labels.max()}\")\n",
    "print(f\"Labels dtype: {labels.dtype}\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f\"batch.keys = {batch.keys()}, \")\n",
    "    break\n",
    "\n",
    "print(train_dataset['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1800dc26",
   "metadata": {},
   "source": [
    "for batch in dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68959c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chkpt(model,version):\n",
    "  return model.load_state_dict(torch.load(f\"./saved_model/securityRoBERTa{version}.0.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526288b9",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_model_peft(trainer,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "  trainer.model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d['input_ids'].to(device)\n",
    "    attention_mask = d['attention_mask'].to(device)\n",
    "    labels = d[\"labels\"].to(device)\n",
    "    \n",
    "    outputs = trainer.model(input_ids,attention_mask, labels=labels)\n",
    "    logits = outputs.logits  # extract the logits tensor\n",
    "    _,preds = torch.max(logits,dim=1)\n",
    "    loss = loss_fn(logits,labels)\n",
    "\n",
    "    correct_predictions+=torch.sum(preds==labels).cpu()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(trainer.model.parameters(),max_norm=1.0)\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions/n_examples,np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70471911",
   "metadata": {},
   "source": [
    "def evaluation_model_peft(trainer,data_loader,loss_fn,device,n_examples):\n",
    "  trainer.model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d['input_ids'].to(device)\n",
    "    attention_mask = d['attention_mask'].to(device)\n",
    "    labels = d['label'].to(device)\n",
    "\n",
    "    outputs = trainer.model(input_ids,attention_mask, labels=labels)\n",
    "    logits = outputs.logits  # extract the logits tensor\n",
    "    _,preds = torch.max(logits,dim=1)\n",
    "    loss = loss_fn(logits,labels)\n",
    "\n",
    "    correct_predictions+=torch.sum(preds==labels).cpu()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions/n_examples,np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "class MetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch_train_losses = []\n",
    "        self.epoch_train_accuracies = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None:\n",
    "            return\n",
    "        \n",
    "        if \"loss\" in logs:\n",
    "            self.epoch_train_losses.append(logs[\"loss\"])\n",
    "\n",
    "        if \"eval_accuracy\" in logs:\n",
    "            self.epoch_train_accuracies.append(logs[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87687bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.history = defaultdict(list)\n",
    "        self.best_val_acc = 0.0\n",
    "\n",
    "    def evaluate_and_save(self, epoch, model_version):\n",
    "        # Evaluate on validation set\n",
    "        metrics = self.evaluate()\n",
    "        print(metrics.keys())\n",
    "        val_acc = metrics[\"eval_accuracy\"]\n",
    "        val_loss = metrics[\"eval_loss\"]\n",
    "        self.history[\"val_acc\"].append(val_acc)\n",
    "        self.history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            self.save_model(f\"./saved_model/{model_version}{epoch+1}.0.pt\")\n",
    "            print(f\"Saved best model at epoch {epoch+1} with val_acc={val_acc:.4f}\")\n",
    "\n",
    "    def log_training_epoch(self, train_loss, train_acc):\n",
    "        self.history[\"train_loss\"].append(train_loss)\n",
    "        self.history[\"train_acc\"].append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_prompt_vera = torch.optim.AdamW(model.parameters(),lr=1e-5)\n",
    "total_steps = len(train_loader)*EPOCHS\n",
    "\n",
    "scheduler_prompt_vera = get_linear_schedule_with_warmup(\n",
    "    optimizer_prompt_vera,\n",
    "    num_warmup_steps= 0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b27086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# output dir \n",
    "model_version = \"securityRoBERTa_BasePromptVeRA_\"\n",
    "model_dir = f\"{model_version}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    run_name=model_version,\n",
    "    output_dir=model_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    num_train_epochs=1,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    logging_dir=f\"{model_dir}/logs\",\n",
    "    fp16=True,  # Enable mixed precision training\n",
    "    dataloader_num_workers=4,  # Adjust based on your CPU capabilities\n",
    "    gradient_checkpointing=True,  # Enable gradient checkpointing to save memory\n",
    "    report_to=\"none\",  # Disable reporting to avoid unnecessary overhead\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e86fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 749,583\n",
      "Total parameters: 147,376,621\n",
      "Percentage of trainable params: 0.51%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# configure Trainer\\ntrainer_prompt_vera = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=train_dataset,\\n    eval_dataset=val_dataset,\\n    compute_metrics=compute_metrics\\n)\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix\n",
    "# The parameters after appling LoRA\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "\"\"\"\n",
    "# designing computing metrics as per our use case. (F1-Macro is essential and log-loss is optional)\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p.predictions, TARGET_LIST\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(TARGET_LIST, predictions)\n",
    "    macro_f1 = f1_score(TARGET_LIST, predictions, average='macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"macro_f1\": macro_f1}\n",
    "\"\"\"\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"macro_f1\": macro_f1}\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\"\"\"\n",
    "# configure Trainer\n",
    "trainer_prompt_vera = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61746313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='863' max='863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [863/863 07:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.802300</td>\n",
       "      <td>2.675023</td>\n",
       "      <td>0.153992</td>\n",
       "      <td>0.017792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1480' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [740/740 09:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eval_loss', 'eval_accuracy', 'eval_macro_f1', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
      "Saved best model at epoch 1 with val_acc=0.1540\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='863' max='863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [863/863 07:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.661200</td>\n",
       "      <td>2.648941</td>\n",
       "      <td>0.153992</td>\n",
       "      <td>0.017792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1480' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [740/740 14:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eval_loss', 'eval_accuracy', 'eval_macro_f1', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='863' max='863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [863/863 12:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.580600</td>\n",
       "      <td>2.638755</td>\n",
       "      <td>0.153992</td>\n",
       "      <td>0.017792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='740' max='740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [740/740 01:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eval_loss', 'eval_accuracy', 'eval_macro_f1', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'epoch'])\n",
      "Training complete and history saved.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "metrics_callback = MetricsCallback()\n",
    "\n",
    "# New trainer\n",
    "trainer_prompt_vera = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Train for one epoch (Trainer handles batches internally)\n",
    "    trainer_prompt_vera.train()\n",
    "\n",
    "    trainer_prompt_vera.log_training_epoch(metrics_callback.epoch_train_losses[-1], metrics_callback.epoch_train_accuracies[-1])\n",
    "\n",
    "    # Evaluate and potentially save best model\n",
    "    trainer_prompt_vera.evaluate_and_save(\n",
    "        epoch,\n",
    "        model_version\n",
    "    )\n",
    "\n",
    "history_roberta_base_prompt_vera = trainer_prompt_vera.history\n",
    "\n",
    "# Save full history and training time\n",
    "end_time = time.time()\n",
    "history_roberta_base_prompt_vera[\"training_time\"].append(end_time - start_time)\n",
    "\n",
    "torch.save(history_roberta_base_prompt_vera, \"./saved_model/history_roberta_base_prompt_vera.pt\")\n",
    "print(\"Training complete and history saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233da18",
   "metadata": {},
   "source": [
    "%%time\n",
    "history_roberta_base_prompt_vera = defaultdict(list)\n",
    "best_accuracy_roberta_base_prompt_vera=0\n",
    "print(\"1\")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "  print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "  train_acc_roberta_base_prompt_vera,train_loss_roberta_base_prompt_vera = train_model_peft(trainer_prompt_vera,train_loader,loss_fn,optimizer_prompt_vera,device,scheduler_prompt_vera,len(train_set))\n",
    "  val_acc_roberta_base_prompt_vera,val_loss_roberta_base_prompt_vera = evaluation_model_peft(trainer_prompt_vera,val_loader,loss_fn,device,len(val_set))\n",
    "  history_roberta_base_prompt_vera['train_acc'].append(train_acc_roberta_base_prompt_vera)\n",
    "  history_roberta_base_prompt_vera['train_loss'].append(train_loss_roberta_base_prompt_vera)\n",
    "  history_roberta_base_prompt_vera['val_acc'].append(val_acc_roberta_base_prompt_vera)\n",
    "  history_roberta_base_prompt_vera['val_loss'].append(val_loss_roberta_base_prompt_vera)\n",
    "  print(f\"Train Loss {train_loss_roberta_base_prompt_vera} | Validation Loss {val_loss_roberta_base_prompt_vera} | Training Accuracy {train_acc_roberta_base_prompt_vera} | Validation Accuracy {val_acc_roberta_base_prompt_vera}\")\n",
    "\n",
    "  if val_acc_roberta_base_prompt_vera>best_accuracy_roberta_base_prompt_vera:\n",
    "    trainer_prompt_vera.save_model(f\"./saved_model/{model_version}{epoch+1}.0.pt\")\n",
    "    best_accuracy_roberta_base_prompt_vera = val_acc_roberta_base_prompt_vera\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "history_roberta_base_prompt_vera['training_time'].append(end_time - start_time)\n",
    "\n",
    "# Save\n",
    "torch.save(history_roberta_base_prompt_vera, \"./saved_model/history_roberta_base_prompt_vera.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.defaultdict'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "history_roberta_base_prompt_vera = torch.load(\"./saved_model/history_roberta_base_prompt_vera.pt\", weights_only=False)\n",
    "\n",
    "# Still a defaultdict with tensors\n",
    "print(type(history_roberta_base_prompt_vera))  # defaultdict\n",
    "print(type(history_roberta_base_prompt_vera['train_acc'][0]))  # torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33331f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.8023, 10.6612, 10.5806]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "epochs = range(1, EPOCHS+1)\n",
    "train_losses = history_roberta_base_prompt_vera['train_loss']\n",
    "print(train_losses)\n",
    "val_losses = history_roberta_base_prompt_vera['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(x=epochs, y=train_losses, label='Training Loss',marker=\"o\")\n",
    "sns.lineplot(x=epochs, y=val_losses, label='Validation Loss',marker=\"o\")\n",
    "\n",
    "plt.title('RoBERTa Base VeRA Prompt Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('./roberta-base-prompt-vera-training-validation-losses.png',dpi=780)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1febc87",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_accuracies \u001b[38;5;241m=\u001b[39m [tens\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m tens \u001b[38;5;129;01min\u001b[39;00m history_roberta_base_prompt_vera[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      3\u001b[0m val_accuracies \u001b[38;5;241m=\u001b[39m [tens\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m tens \u001b[38;5;129;01min\u001b[39;00m history_roberta_base_prompt_vera[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "epochs = range(1, EPOCHS+1)\n",
    "train_accuracies = [tens.item() for tens in history_roberta_base_prompt_vera['train_acc']]\n",
    "val_accuracies = [tens.item() for tens in history_roberta_base_prompt_vera['val_acc']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(x=epochs, y=train_accuracies, label='Training accuracy',marker='o')\n",
    "sns.lineplot(x=epochs, y=val_accuracies, label='Validation accuracy',marker='o')\n",
    "\n",
    "plt.title('RoBERTa Base VeRA Prompt Training and Validation Accuracies')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('./roberta-base-prompt-vera-training-validation-accuracies.png',dpi=780)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d803d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import PredictionOutput\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "def get_predictions(trainer, test_dataset):\n",
    "    # Runs prediction\n",
    "    output: PredictionOutput = trainer.predict(test_dataset)\n",
    "\n",
    "    # Get raw logits and labels\n",
    "    logits = torch.tensor(output.predictions)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "    labels = torch.tensor(output.label_ids)\n",
    "\n",
    "    return preds, probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, probs, labels = get_predictions(trainer_prompt_vera, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4510d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(preds,\"./saved_model/roberta_base_prompt_vera_predictions.pt\")\n",
    "torch.save(probs,\"./saved_model/roberta_base_prompt_vera_predictions_probs.pt\")\n",
    "torch.save(labels,\"./saved_model/roberta_base_prompt_vera_real_values.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Backdoor', 'DDoS_HTTP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_UDP',\n",
    "       'Fingerprinting', 'MITM', 'Normal', 'Password', 'Port_Scanning',\n",
    "       'Ransomware', 'SQL_injection', 'Uploading', 'Vulnerability_scanner',\n",
    "       'XSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in preds:\n",
    "  s.add(elt.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6825de",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_considered_classes = [TARGET_LIST[i] for i in s]\n",
    "actual_considered_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e02f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"RoBERTa Base VeRA Prompt Confusion Matrix\")\n",
    "    plt.ylabel('Real threats')\n",
    "    plt.xlabel('Predicted threats')\n",
    "    plt.savefig('./roberta-base-prompt-vera-confusion-matrix.png',dpi=780)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d11d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels,preds,target_names=TARGET_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab68a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels,preds)\n",
    "df_cm = pd.DataFrame(cm,index=TARGET_LIST,columns=TARGET_LIST)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0881076",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labels.cpu().numpy()\n",
    "y_score = preds.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
