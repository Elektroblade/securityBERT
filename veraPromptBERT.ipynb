{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edefa5c4",
   "metadata": {},
   "source": [
    "https://medium.com/rahasak/fine-tune-llm-for-real-time-network-attach-detection-with-apple-mlx-b6c70f5c843a\n",
    "Also used code from https://gitlab.com/rahasak-labs/mlxa/-/blob/master/data/prepare.py?ref_type=heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02e8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer,get_linear_schedule_with_warmup,RobertaTokenizer,BertForSequenceClassification,BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import get_peft_model\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a581e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecurityBERT(nn.Module):\n",
    "  def __init__(self,myTunedBERT,n_classes):\n",
    "    super(SecurityBERT,self).__init__()\n",
    "    self.bert = myTunedBERT\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size,n_classes)\n",
    "    self.config = self.bert.config\n",
    "    self.gradient_checkpointing_enable = self.bert.gradient_checkpointing_enable\n",
    "\n",
    "  def forward(self,input_ids,attention_mask,token_type_ids=None,labels=None):\n",
    "    pooled_output = self.bert(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids,\n",
    "        return_dict=True\n",
    "    ).pooler_output\n",
    "\n",
    "    output = pooled_output.last_hidden_state[:, 0, :]\n",
    "    output = self.dropout(output)\n",
    "\n",
    "    return self.out(output)\n",
    "  \n",
    "def print_trainable_parameters(model):\n",
    "    if isinstance(model,SecurityBERT):\n",
    "        trainable = sum(p.numel() for p in model.bert.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Percentage of trainable params: {100 * trainable / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6500b",
   "metadata": {},
   "source": [
    "## Set up model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adfbe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at gaunernst/bert-tiny-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.53.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Trainable parameters: 4,386,178\n",
      "Total parameters: 4,386,178\n",
      "Percentage of trainable params: 100.00%\n",
      "Number of available GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gaunernst/bert-tiny-uncased\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "print(model.config)\n",
    "print_trainable_parameters(model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886df213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_check():\n",
    "  return round(psutil.virtual_memory().used/1024**3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3a926",
   "metadata": {},
   "source": [
    "## PEFT Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb89eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 544\n",
      "Total parameters: 4,386,722\n",
      "Percentage of trainable params: 0.01%\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, VeraConfig, TaskType\n",
    "\n",
    "# Define VeRA configuration\n",
    "config = VeraConfig(\n",
    "    r=8,  # Low-rank decomposition size\n",
    "    target_modules=[\"query\", \"value\"],  # Specify target modules\n",
    "    vera_dropout=0.2,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# Apply VeRA adapter\n",
    "#model = model.prepare_model_for_kbit_training()\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b15a8",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ba8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_pickle('./saved_data/encoded_data.pck')\n",
    "le = LabelEncoder()\n",
    "data['target'] = le.fit_transform(data['Attack_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650b3a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_PPFLE</th>\n",
       "      <th>Attack_type</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19455</th>\n",
       "      <td>002d2b854e822b14a12d5748f884d26516b85a8d 0bc16...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50405</th>\n",
       "      <td>93541bde5bc09c562e19d577ab3146c0f1956135 a9183...</td>\n",
       "      <td>DDoS_TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70956</th>\n",
       "      <td>696d286c6af9e7a938c62b922c37fa35dad90b5a e8d5c...</td>\n",
       "      <td>Port_Scanning</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120219</th>\n",
       "      <td>9857f0b348da8ad969462c44942d888a2c76d396 0bc16...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94423</th>\n",
       "      <td>d484978978cb10a79b018792df9f798df384ddf0 0bc16...</td>\n",
       "      <td>Backdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90226</th>\n",
       "      <td>918f3468eb2e4c373133963eb914f7c312c68984 0bc16...</td>\n",
       "      <td>Backdoor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136853</th>\n",
       "      <td>4ed8c519f7a3e1c0c1cac2d67ec601835bf84ca1 5f363...</td>\n",
       "      <td>DDoS_UDP</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34485</th>\n",
       "      <td>e70b2a9bec51fc94af8bfeffb1bb233b37dcb03c 6df8d...</td>\n",
       "      <td>DDoS_HTTP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4585</th>\n",
       "      <td>1337f298a85ff9993a639c3a133ba5da8c0e4a2e 0bc16...</td>\n",
       "      <td>Ransomware</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96105</th>\n",
       "      <td>924313e8b7c056ff4114f456abda1df03f49971f 0bc16...</td>\n",
       "      <td>XSS</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97514</th>\n",
       "      <td>7c338269e5c9454183c4e8a94999734c322cb2b0 0bc16...</td>\n",
       "      <td>XSS</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84562</th>\n",
       "      <td>b732b55e17952c9827fc02afaaaebc42c10a1c1f 0bc16...</td>\n",
       "      <td>Vulnerability_scanner</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142337</th>\n",
       "      <td>3a2edf1d947ac0137a1fabb5b6ee2d8dae430966 0bc16...</td>\n",
       "      <td>DDoS_UDP</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111723</th>\n",
       "      <td>f8981b5ec6d47e62cb95fa9643de64d3060ecf50 e8d5c...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74504</th>\n",
       "      <td>45dab325fc292df07ad7cd28bb911209592143e3 6df8d...</td>\n",
       "      <td>Port_Scanning</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            encoded_PPFLE  \\\n",
       "19455   002d2b854e822b14a12d5748f884d26516b85a8d 0bc16...   \n",
       "50405   93541bde5bc09c562e19d577ab3146c0f1956135 a9183...   \n",
       "70956   696d286c6af9e7a938c62b922c37fa35dad90b5a e8d5c...   \n",
       "120219  9857f0b348da8ad969462c44942d888a2c76d396 0bc16...   \n",
       "94423   d484978978cb10a79b018792df9f798df384ddf0 0bc16...   \n",
       "90226   918f3468eb2e4c373133963eb914f7c312c68984 0bc16...   \n",
       "136853  4ed8c519f7a3e1c0c1cac2d67ec601835bf84ca1 5f363...   \n",
       "34485   e70b2a9bec51fc94af8bfeffb1bb233b37dcb03c 6df8d...   \n",
       "4585    1337f298a85ff9993a639c3a133ba5da8c0e4a2e 0bc16...   \n",
       "96105   924313e8b7c056ff4114f456abda1df03f49971f 0bc16...   \n",
       "97514   7c338269e5c9454183c4e8a94999734c322cb2b0 0bc16...   \n",
       "84562   b732b55e17952c9827fc02afaaaebc42c10a1c1f 0bc16...   \n",
       "142337  3a2edf1d947ac0137a1fabb5b6ee2d8dae430966 0bc16...   \n",
       "111723  f8981b5ec6d47e62cb95fa9643de64d3060ecf50 e8d5c...   \n",
       "74504   45dab325fc292df07ad7cd28bb911209592143e3 6df8d...   \n",
       "\n",
       "                  Attack_type  Attack_label  target  \n",
       "19455               Uploading             1      12  \n",
       "50405                DDoS_TCP             1       3  \n",
       "70956           Port_Scanning             1       9  \n",
       "120219                 Normal             0       7  \n",
       "94423                Backdoor             1       0  \n",
       "90226                Backdoor             1       0  \n",
       "136853               DDoS_UDP             1       4  \n",
       "34485               DDoS_HTTP             1       1  \n",
       "4585               Ransomware             1      10  \n",
       "96105                     XSS             1      14  \n",
       "97514                     XSS             1      14  \n",
       "84562   Vulnerability_scanner             1      13  \n",
       "142337               DDoS_UDP             1       4  \n",
       "111723                 Normal             0       7  \n",
       "74504           Port_Scanning             1       9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3e00cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'689e1d00f39f485bd2da5098239199df85c39b4d 2ab932d3aadb7887eda7302e0b33df13dc5ca645 f2c86566785eaad29f5c4b244d058b0cb7deb97e 5ea155b76662c1b381a0526e87d733a2ae68bfce b3625a98258ceacc69889389baca3b048a4923e4 8d419a4b06c3bd95d00fe2ee5cf1146851cf9893 c71f6d1e2daf2f598381088226df35ae68552f0b b7036347f54fa5aef0dd3f66b4e44c56bbf54cf4 f97d947902327761a4b1472d76b71bf4406e4e18 79ae7b95cace51fb0079d9c5ef1641f4639ce3ed ea25a11eb9c83b7d70252710098ded6bc81eb62b ceae604760aaa4fd8b60791ae1839b754c2dd9f1 23197a0ba8a217f2bc8711ec3c4be39dc19236d7 e2df55df19acd4423bafccbb0b8a385ec5e914eb f086df09fafdda401160bc766631e3d5785a6257 5329d5d159837e103352035068b3e14ce570d7eb 3eb6e4b9dd1c085a3ad0b18484d48482c935a4f7 943315f7b6cb0fc45604f5cf2ac307894e59b990 89b029338e8dd73f49369cd01c0052663c8c949e f91e2919e7494d796d1148066124d4b4939c86fa a5ce077c8900f85e073032ae975d95491645ddce effcfb2aa80217f507218ea88726c9325a0d68b9 bf12d74b6502b4fc1e29df164d3bf6f6ce51ffe3 7d69c36dbc4a37fc6643a32e914ea4e7ee0f0fc2 128f4c3fdc8539ea887fc54fe41fb2654e61d21e cf09211f8fce92ebb8209ea5703c84c95adababf 527ff8dab3e2a9038784c4498898f385d37c8bbf 25228e41a07fb6337440bcd65bf610730baee1ad 2bb8fbd462d958539a98c45da70be02731b9c83d e08c348b0a504bcd8779123ba7fca91b068ab03c e3773f9e7df4f1e1ac4a50cc8c7ad74dcfa5caea afb3c4e997ed979faa4be5b9acdfa907baf289bc 8c013b2163fe03dbadcbebe166b14f5eaa7b696b 609efeabea8e6b3209a269279f8981c91e174f55 9d8f0cbe88bc5a9c776d85c62f93520e64171b87 ac85af4c5313ae22e35f29e0ad4cc7d859d4b73a 471a1d5c286644db75306d1d9c9cbe5249f4e98e 10ded1179d3349c7594e5117de982d951d4de1fc 1aea5dc09556ef08f620c7b8d3a816e9a812e9c3 321d843de46a66adf2f508493b803187b9f3a488 2dadbb6a5bb73f1bc9a604a27ed3d9e47ab23299 20bf31a2b3be346947648c9c27876bc5f8b50de4 0e24afc14051165f920027d89f9f2185037c3654 15ba9de63999d8f46389024fc2f1c6ed7a3e51f1 fafed74d6fbd09b6f066aa83ba4a38e30e4379c5 094658d5fc003bad5c085219ff65122ddc885f1d 836658e7678c4b7410183ed50b0e263ebd6665bf df02b7c8b68f6ec003c80d1c814f037dfcd55b9f 14520d20adff40fb27695aae63868abe56dcaf25 d4ec9f131ac9b992101f89975d1aa9525f50faac c670faa4b0c2f337be3a5dd7023896927af82abb 5d4aa9cc3a38425b4861a39bf306f278c34c5915 33ff04f381603ec87b266a7f7d8ee63230d3ab4d 6c688e57ffaaa3e0f6b832b1698a0e0b4e166df9 fd64ac0598fbeb73ed97cf30b69998dcc1c7a55c 7ff6f594e600ece857707fa8b01534124647de42 7f7f4bd794be0a8e3ad16af50933b3725c30443a 1b3388c83b9ea78221c264bc4bd2b9ed163df9c5 4d2fc9148ddb9459165087751a8d0b6bb846681a afc155dfb40593981720bbd50f68eaf71891b9dd 4eb7e229a7ed9d2c82281d958731e5237b422651'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['encoded_PPFLE'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428603e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(data['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9154124f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.144"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ea4770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86521ce07736435991859d07168dc35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"encoded_data.txt\",\"w\") as f:\n",
    "  for value in tqdm(data['encoded_PPFLE']):\n",
    "    f.write(str(value)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d89235",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompt_encoded_data.txt\",\"w\") as f:\n",
    "    for _, row in data.iterrows():\n",
    "        f.write(f\"You are an expert in network traffic classification. Based on the provided network traffic attributes, you must determine whether the traffic is \" +\n",
    "                f\"'Backdoor', 'DDoS_HTTP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_UDP', 'Fingerprinting', 'MITM', 'Normal', 'Password', 'Port_Scanning', 'Ransomware', 'SQL_injection', 'Uploading', \" + \n",
    "                f\"'Vulnerability_scanner', or 'XSS'. Here are the encoded attributes, 'encoded_PPFLE: {row['encoded_PPFLE']}'. \" + '\\n')\n",
    "#'<s>','<pad>','</s>','<unk>','<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e95768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_PPFLE_prompt</th>\n",
       "      <th>Attack_type</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133191</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_UDP</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53735</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_TCP</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156917</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_ICMP</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137156</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_UDP</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32708</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>SQL_injection</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97655</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>XSS</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30199</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>SQL_injection</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64721</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Port_Scanning</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118195</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57194</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Password</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103022</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>XSS</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124446</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109458</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43927</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_HTTP</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134080</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>DDoS_UDP</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     encoded_PPFLE_prompt    Attack_type  \\\n",
       "133191  You are an expert in network traffic classific...       DDoS_UDP   \n",
       "53735   You are an expert in network traffic classific...       DDoS_TCP   \n",
       "156917  You are an expert in network traffic classific...      DDoS_ICMP   \n",
       "137156  You are an expert in network traffic classific...       DDoS_UDP   \n",
       "32708   You are an expert in network traffic classific...  SQL_injection   \n",
       "97655   You are an expert in network traffic classific...            XSS   \n",
       "30199   You are an expert in network traffic classific...  SQL_injection   \n",
       "64721   You are an expert in network traffic classific...  Port_Scanning   \n",
       "118195  You are an expert in network traffic classific...         Normal   \n",
       "57194   You are an expert in network traffic classific...       Password   \n",
       "103022  You are an expert in network traffic classific...            XSS   \n",
       "124446  You are an expert in network traffic classific...         Normal   \n",
       "109458  You are an expert in network traffic classific...         Normal   \n",
       "43927   You are an expert in network traffic classific...      DDoS_HTTP   \n",
       "134080  You are an expert in network traffic classific...       DDoS_UDP   \n",
       "\n",
       "        Attack_label  target  \n",
       "133191             1       4  \n",
       "53735              1       3  \n",
       "156917             1       2  \n",
       "137156             1       4  \n",
       "32708              1      11  \n",
       "97655              1      14  \n",
       "30199              1      11  \n",
       "64721              1       9  \n",
       "118195             0       7  \n",
       "57194              1       8  \n",
       "103022             1      14  \n",
       "124446             0       7  \n",
       "109458             0       7  \n",
       "43927              1       1  \n",
       "134080             1       4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"prompt_encoded_data.txt\", \"r\") as f:\n",
    "    prompt_lines = f.readlines()\n",
    "\n",
    "# Strip newline characters\n",
    "prompt_lines = [prompt_line.strip() for prompt_line in prompt_lines]\n",
    "prompt_data = {\n",
    "    \"encoded_PPFLE_prompt\": prompt_lines, 'Attack_type': data['Attack_type'], 'Attack_label': data['Attack_label'], 'target': data['target']\n",
    "}\n",
    "prompt_df = pd.DataFrame(prompt_data)\n",
    "prompt_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d874219",
   "metadata": {},
   "source": [
    "class BertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "dataset = BertDataset(encodings, list(df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e43284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110460, 4) (23670, 4) (23670, 4)\n"
     ]
    }
   ],
   "source": [
    "train_set = prompt_df.sample(frac=0.7,random_state=42).reset_index(drop=True)\n",
    "\n",
    "remaining = prompt_df.drop(train_set.index).reset_index(drop=True)\n",
    "\n",
    "test_set = remaining.sample(frac=0.5,random_state=42).reset_index(drop=True)\n",
    "\n",
    "val_set = remaining.drop(test_set.index).reset_index(drop=True)\n",
    "\n",
    "print(train_set.shape,val_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8702316",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_set, test_set = train_test_split(prompt_df, test_size=test_ratio,stratify=prompt_df.iloc[:,-1], random_state=42)\n",
    "train_set, val_set = train_test_split(train_set, test_size=val_ratio/(val_ratio+train_ratio),stratify=train_set.iloc[:,-1], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34b9833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110460, 4), (23670, 4), (23670, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape,val_set.shape,test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bfca417",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LIST = ['Backdoor', 'DDoS_HTTP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_UDP',\n",
    "                'Fingerprinting', 'MITM', 'Normal', 'Password', 'Port_Scanning',\n",
    "                'Ransomware', 'SQL_injection', 'Uploading', 'Vulnerability_scanner',\n",
    "                'XSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bf22757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_PPFLE_prompt</th>\n",
       "      <th>Attack_type</th>\n",
       "      <th>Attack_label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13140</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13141</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13142</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13143</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>You are an expert in network traffic classific...</td>\n",
       "      <td>Uploading</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    encoded_PPFLE_prompt Attack_type  \\\n",
       "13140  You are an expert in network traffic classific...   Uploading   \n",
       "13141  You are an expert in network traffic classific...   Uploading   \n",
       "13142  You are an expert in network traffic classific...   Uploading   \n",
       "13143  You are an expert in network traffic classific...   Uploading   \n",
       "13144  You are an expert in network traffic classific...   Uploading   \n",
       "\n",
       "       Attack_label  target  \n",
       "13140             1      12  \n",
       "13141             1      12  \n",
       "13142             1      12  \n",
       "13143             1      12  \n",
       "13144             1      12  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_df[prompt_df['Attack_type']=='Uploading'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d5194fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self,encodings,df,max_len):\n",
    "    self.encodings = encodings\n",
    "    self.df = df\n",
    "    self.max_len=max_len\n",
    "    self.targets = self.df['target'].tolist()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    target = self.targets[idx]\n",
    "    encoding = self.encodings[idx]\n",
    "\n",
    "    return {\n",
    "        'input_ids':encoding['input_ids'].flatten(),\n",
    "        'attention_mask':encoding['attention_mask'].flatten(),\n",
    "        'targets':torch.tensor(target,dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bde821",
   "metadata": {},
   "source": [
    "import tokenizers\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"gaunernst/bert-tiny-uncased\")\n",
    "\n",
    "# Tokenize the text\n",
    "train_set_enc = tokenizer(list(train_set[\"encoded_PPFLE_prompt\"]), truncation=True, padding=True)\n",
    "val_set_enc = tokenizer(list(val_set[\"encoded_PPFLE_prompt\"]), truncation=True, padding=True)\n",
    "test_set_enc = tokenizer(list(test_set[\"encoded_PPFLE_prompt\"]), truncation=True, padding=True)\n",
    "\n",
    "torch.save(train_set_enc, 'vera_prompt_bert_train_encodings.pt')\n",
    "torch.save(val_set_enc, 'vera_prompt_bert_val_encodings.pt')\n",
    "torch.save(test_set_enc, 'vera_prompt_bert_test_encodings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df2f0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_enc = torch.load('vera_prompt_bert_train_encodings.pt', weights_only=False)\n",
    "val_set_enc = torch.load('vera_prompt_bert_val_encodings.pt', weights_only=False)\n",
    "test_set_enc = torch.load('vera_prompt_bert_test_encodings.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6dbc19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=512\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_dataset = CustomDataset(train_set_enc,df=train_set,max_len=MAX_LEN)\n",
    "val_dataset = CustomDataset(val_set_enc,df=val_set,max_len=MAX_LEN)\n",
    "test_dataset = CustomDataset(test_set_enc,df=test_set,max_len=MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f83d27b",
   "metadata": {},
   "source": [
    "test_data = next(iter(train_loader))\n",
    "\n",
    "print(test_data['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37ece3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chkpt(model,version):\n",
    "  return model.load_state_dict(torch.load(f\"./saved_model/securityBert{version}.0.pt\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79d8d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_model_peft(trainer,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
    "  trainer.train()\n",
    "\n",
    "  print(\"after\")\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d['input_ids'].to(device)\n",
    "    attention_mask = d['attention_mask'].to(device)\n",
    "    targets = d['targets'].to(device)\n",
    "    print(\"the\")\n",
    "\n",
    "    outputs = trainer.model(input_ids,attention_mask)\n",
    "    _,preds = torch.max(outputs,dim=1)\n",
    "    loss = loss_fn(outputs,targets)\n",
    "\n",
    "    correct_predictions+=torch.sum(preds==targets).cpu()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(trainer.model.parameters(),max_norm=1.0)\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions/n_examples,np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8e619e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_model_peft(trainer,data_loader,loss_fn,device,n_examples):\n",
    "  trainer.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d['input_ids'].to(device)\n",
    "    attention_mask = d['attention_mask'].to(device)\n",
    "    targets = d['targets'].to(device)\n",
    "\n",
    "    outputs = trainer.model(input_ids,attention_mask)\n",
    "    _,preds = torch.max(outputs,dim=1)\n",
    "\n",
    "    loss = loss_fn(outputs,targets)\n",
    "\n",
    "    correct_predictions+=torch.sum(preds==targets).cpu()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions/n_examples,np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b23ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "securityBertTinyPromptVera = SecurityBERT(myTunedBERT=model,n_classes=len(TARGET_LIST)).to(device)\n",
    "EPOCHS=3\n",
    "optimizer_prompt_vera = torch.optim.AdamW(securityBertTinyPromptVera.parameters(),lr=1e-5)\n",
    "total_steps = len(train_loader)*EPOCHS\n",
    "\n",
    "scheduler_prompt_vera = get_linear_schedule_with_warmup(\n",
    "    optimizer_prompt_vera,\n",
    "    num_warmup_steps= 0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333462d",
   "metadata": {},
   "source": [
    "dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28d5697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# output dir \n",
    "model_version = \"securityBert_TinyPromptVeRA_\"\n",
    "model_dir = f\"{model_version}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    run_name=model_version,\n",
    "    output_dir=model_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    num_train_epochs=1,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    logging_dir=f\"{model_dir}/logs\",\n",
    "    fp16=True,  # Enable mixed precision training\n",
    "    dataloader_num_workers=4,  # Adjust based on your CPU capabilities\n",
    "    gradient_checkpointing=True,  # Enable gradient checkpointing to save memory\n",
    "    report_to=\"none\"  # Disable reporting to avoid unnecessary overhead\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1362e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially remove\n",
    "\n",
    "#securityBertTinyPromptVera.bert.gradient_checkpointing_enable()\n",
    "#securityBertTinyPromptVera = prepare_model_for_kbit_training(securityBertTinyPromptVera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23553dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 544\n",
      "Total parameters: 4,386,722\n",
      "Percentage of trainable params: 0.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix\n",
    "# The parameters after appling LoRA\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# designing computing metrics as per our use case. (F1-Macro is essential and log-loss is optional)\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p.predictions, TARGET_LIST\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(TARGET_LIST, predictions)\n",
    "    macro_f1 = f1_score(TARGET_LIST, predictions, average='macro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"macro_f1\": macro_f1}\n",
    "\n",
    "# configure Trainer\n",
    "trainer_prompt_vera = Trainer(\n",
    "    model=securityBertTinyPromptVera,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2fa6d2",
   "metadata": {},
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from collections import defaultdict\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11a9e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens: 110460\n",
      "Average tokens: 110460.00\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"gaunernst/bert-tiny-uncased\")\n",
    "lengths = []\n",
    "\n",
    "for example in train_set[\"encoded_PPFLE_prompt\"]:  # Adjust to your dataset key\n",
    "    lengths.append(len(train_set_enc[\"input_ids\"]))\n",
    "\n",
    "print(f\"Max tokens: {max(lengths)}\")\n",
    "print(f\"Average tokens: {sum(lengths)/len(lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bdd646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5e4049758f4bd5bf4c7a9d88fe7f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_tiny_prompt_vera = defaultdict(list)\n",
    "best_accuracy_tiny_prompt_vera=0\n",
    "print(\"1\")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "  print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "  train_acc_tiny_prompt_vera,train_loss_tiny_prompt_vera = train_model_peft(trainer_prompt_vera,train_loader,loss_fn,optimizer_prompt_vera,device,scheduler_prompt_vera,len(train_set))\n",
    "  val_acc_tiny_prompt_vera,val_loss_tiny_prompt_vera = evaluation_model_peft(trainer_prompt_vera,val_loader,loss_fn,device,len(val_set))\n",
    "  history_tiny_prompt_vera['train_acc'].append(train_acc_tiny_prompt_vera)\n",
    "  history_tiny_prompt_vera['train_loss'].append(train_loss_tiny_prompt_vera)\n",
    "  history_tiny_prompt_vera['val_acc'].append(val_acc_tiny_prompt_vera)\n",
    "  history_tiny_prompt_vera['val_loss'].append(val_loss_tiny_prompt_vera)\n",
    "  print(f\"Train Loss {train_loss_tiny_prompt_vera} | Validation Loss {val_loss_tiny_prompt_vera} | Training Accuracy {train_acc_tiny_prompt_vera} | Validation Accuracy {val_acc_tiny_prompt_vera}\")\n",
    "\n",
    "  if val_acc_tiny_prompt_vera>best_accuracy_tiny_prompt_vera:\n",
    "    trainer.save_model(f\"./saved_model/{model_version}{epoch+1}.0.pt\")\n",
    "    best_accuracy_tiny_prompt_vera = val_acc_tiny_prompt_vera\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "history_tiny_prompt_vera['training_time'].append(end_time - start_time)\n",
    "\n",
    "# Convert to regular dict and save as JSON\n",
    "with open(\"./saved_model/history_tiny_prompt_vera.txt\", \"w\") as f:\n",
    "    json.dump(history_tiny_prompt_vera, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a099528c",
   "metadata": {},
   "source": [
    "Stopped trying to tune BERT-mini-uncased pre-trained, using QDoRA at 987 minutes. Did not get past first epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91371ef",
   "metadata": {},
   "source": [
    "Stopped trying to tune BERT-tiny-uncased pre-trained, using VeRA at 963 minutes. Did not get past first epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4256a8",
   "metadata": {},
   "source": [
    "Stopped trying to tune BERT-tiny-uncased pre-trained, using VeRA (r = 8) with Edge-IIoT in sentence prompt format tokenized by bert-base-uncased at 607 minutes. Did not get past first epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627574f",
   "metadata": {},
   "source": [
    "-Obtaining prompt encodings took 44 minutes with BERT-base-uncased\n",
    "\n",
    "-57 min 23 sec with BERT-tiny-uncased\n",
    "\n",
    "-1 min 7 sec with RoBERTa-base using batched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4e20f",
   "metadata": {},
   "source": [
    "Obtained the result that each prompt is undergoing token explosion, expected to be on the out-of-language tokens, for a max and average of 110460 tokens per prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c5b07",
   "metadata": {},
   "source": [
    "RoBERTa with r=8 has 294,912 parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3a973",
   "metadata": {},
   "source": [
    "RoBERTa with r=6 has 221,184 trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON and convert back to defaultdict\n",
    "with open(\"./saved_model/history_tiny_prompt_vera.txt\", \"r\") as f:\n",
    "    history_tiny_prompt_vera_json = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
