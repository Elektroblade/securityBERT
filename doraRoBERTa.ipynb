{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13462dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer,get_linear_schedule_with_warmup,RobertaTokenizer,BertForSequenceClassification,BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import get_peft_model\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e004ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Percentage of trainable params: {100 * trainable / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a80d5",
   "metadata": {},
   "source": [
    "## Custom RoBERTa class needs work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification\n",
    "import torch.nn as nn\n",
    "\n",
    "class RobertaForSequenceClassificationWithCustomHead(RobertaForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.custom_layer = nn.Sequential(\n",
    "            nn.Linear(config.num_labels, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, config.num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        accepted_keys = {\n",
    "            \"input_ids\", \"attention_mask\", \"labels\", \"token_type_ids\",\n",
    "            \"position_ids\", \"head_mask\", \"inputs_embeds\", \"output_attentions\",\n",
    "            \"output_hidden_states\", \"return_dict\"\n",
    "        }\n",
    "        filtered_kwargs = {k: v for k, v in kwargs.items() if k in accepted_keys}\n",
    "\n",
    "        outputs = super().forward(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            **filtered_kwargs\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Move custom layer to correct device if needed\n",
    "        if next(self.custom_layer.parameters()).device != logits.device:\n",
    "            self.custom_layer.to(logits.device)\n",
    "\n",
    "        custom_logits = self.custom_layer(logits)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(custom_logits, labels)\n",
    "\n",
    "        return type(outputs)(\n",
    "            loss=loss,\n",
    "            logits=custom_logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import RobertaForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "device\n",
    "model = RobertaForSequenceClassificationWithCustomHead.from_pretrained(\"roberta-base\", num_labels=15, device_map=\"auto\")\n",
    "print(model.config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# Custom tokenizer trained on OOL tokens\n",
    "custom_tokenizer = RobertaTokenizer.from_pretrained('./tokenizer') # Try to remove Fast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vocab = set(custom_tokenizer.get_vocab().keys())\n",
    "\n",
    "new_tokens = list(custom_vocab)\n",
    "\n",
    "print(f\"Found {len(new_tokens)} new tokens to use.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(custom_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,     # or SEQ_2_SEQ_LM, TOKEN_CLS, etc.\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.2,\n",
    "    target_modules=[\"query\", \"key\", \"value\"],  # Adjust for RoBERTa\n",
    "    use_dora=True\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c03425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_pickle('./saved_data/encoded_data.pck')\n",
    "le = LabelEncoder()\n",
    "data['target'] = le.fit_transform(data['Attack_type'])\n",
    "\n",
    "data2 = pd.read_csv(\".\\data\\Edge-IIoTset dataset\\Selected dataset for ML and DL\\ML-EdgeIIoT-dataset.csv\")\n",
    "columns = list(data2.columns[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b43492",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"column_name_encoded_data.txt\",\"w\") as f:\n",
    "    for _, row in data.iterrows():\n",
    "        tokens = row['encoded_PPFLE'].split(\" \")\n",
    "        formatted = []\n",
    "        for idx, (col, tok) in enumerate(zip(columns, tokens)):\n",
    "            end_char = \".\" if idx == len(tokens) - 1 else \";\"\n",
    "            formatted.append(f\"{col}: {tok}{end_char}\")\n",
    "        row_string = \" \".join(formatted)\n",
    "        f.write(row_string + \"\\n\")\n",
    "#'<s>','<pad>','</s>','<unk>','<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2841cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"column_name_encoded_data.txt\", \"r\") as f:\n",
    "    prompt_lines = f.readlines()\n",
    "\n",
    "# Strip newline characters\n",
    "prompt_lines = [prompt_line.strip() for prompt_line in prompt_lines]\n",
    "prompt_data = {\n",
    "    \"encoded_PPFLE_prompt\": prompt_lines, 'Attack_type': data['Attack_type'], 'Attack_label': data['Attack_label'], 'target': data['target']\n",
    "}\n",
    "prompt_df = pd.DataFrame(prompt_data)\n",
    "prompt_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccdbe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = prompt_df.sample(frac=0.7,random_state=42).reset_index(drop=True)\n",
    "\n",
    "remaining = prompt_df.drop(train_set.index).reset_index(drop=True)\n",
    "\n",
    "test_set = remaining.sample(frac=0.5,random_state=42).reset_index(drop=True)\n",
    "\n",
    "val_set = remaining.drop(test_set.index).reset_index(drop=True)\n",
    "\n",
    "print(train_set.shape,val_set.shape,test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a459bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_set, test_set = train_test_split(prompt_df, test_size=test_ratio,stratify=prompt_df.iloc[:,-1], random_state=42)\n",
    "train_set, val_set = train_test_split(train_set, test_size=val_ratio/(val_ratio+train_ratio),stratify=train_set.iloc[:,-1], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07865133",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.shape,val_set.shape,test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184962cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LIST = ['Backdoor', 'DDoS_HTTP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_UDP',\n",
    "                'Fingerprinting', 'MITM', 'Normal', 'Password', 'Port_Scanning',\n",
    "                'Ransomware', 'SQL_injection', 'Uploading', 'Vulnerability_scanner',\n",
    "                'XSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_df[prompt_df['Attack_type']=='Uploading'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b0006",
   "metadata": {},
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self,encodings,df,max_len):\n",
    "    self.encodings = encodings\n",
    "    self.df = df\n",
    "    self.max_len=max_len\n",
    "    self.targets = self.df['target'].tolist()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    target = self.targets[idx]\n",
    "    encoding = self.encodings[idx]\n",
    "\n",
    "    return {\n",
    "        'input_ids':encoding['input_ids'].flatten(),\n",
    "        'attention_mask':encoding['attention_mask'].flatten(),\n",
    "        'targets':torch.tensor(target,dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc04197c",
   "metadata": {},
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import RobertaTokenizerFast\n",
    "import torch\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_function(row):\n",
    "    return custom_tokenizer(\n",
    "        row[\"encoded_PPFLE_prompt\"],               # replace with your actual column\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize entire dataset\n",
    "train_set_enc = (Dataset.from_pandas(train_set)).map(tokenize_function, batched=True)\n",
    "val_set_enc = (Dataset.from_pandas(val_set)).map(tokenize_function, batched=True)\n",
    "test_set_enc = (Dataset.from_pandas(test_set)).map(tokenize_function, batched=True)\n",
    "\n",
    "# Save to disk (recommended)\n",
    "train_set_enc.save_to_disk('lora_roberta_train_encodings.pt')\n",
    "val_set_enc.save_to_disk('lora_roberta_val_encodings.pt')\n",
    "test_set_enc.save_to_disk('lora_roberta_test_encodings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c34ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "train_set_enc = load_from_disk('lora_roberta_train_encodings.pt')\n",
    "print(len(train_set_enc))\n",
    "val_set_enc = load_from_disk('lora_roberta_val_encodings.pt')\n",
    "print(len(val_set_enc))\n",
    "test_set_enc = load_from_disk('lora_roberta_test_encodings.pt')\n",
    "print(len(test_set_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dataset_format(dataset):\n",
    "    dataset = dataset.rename_column('target', \"labels\")\n",
    "    dataset.set_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"]  # include \"labels\" column\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = set_dataset_format(train_set_enc)\n",
    "val_dataset = set_dataset_format(val_set_enc)\n",
    "test_dataset = set_dataset_format(test_set_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=512\n",
    "BATCH_SIZE=32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0\n",
    "\n",
    ")\n",
    "\n",
    "test_data = next(iter(train_loader))\n",
    "\n",
    "print(test_data['input_ids'].shape)\n",
    "\n",
    "labels = train_dataset[\"labels\"]\n",
    "print(f\"Labels min, max: {labels.min(), labels.max()}\")\n",
    "print(f\"Labels dtype: {labels.dtype}\")\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f\"batch.keys = {batch.keys()}, \")\n",
    "    break\n",
    "\n",
    "print(train_dataset['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68959c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chkpt(model,version):\n",
    "  return model.load_state_dict(torch.load(f\"./saved_model/securityRoBERTa{version}.0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "class MetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch_train_losses = []\n",
    "        self.epoch_train_accuracies = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is None:\n",
    "            return\n",
    "        \n",
    "        if \"loss\" in logs:\n",
    "            self.epoch_train_losses.append(logs[\"loss\"])\n",
    "\n",
    "        if \"eval_accuracy\" in logs:\n",
    "            self.epoch_train_accuracies.append(logs[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87687bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.history = defaultdict(list)\n",
    "        self.best_val_acc = 0.0\n",
    "\n",
    "    def evaluate_and_save(self, epoch, model_version):\n",
    "        # Evaluate on validation set\n",
    "        metrics = self.evaluate()\n",
    "        print(metrics.keys())\n",
    "        val_acc = metrics[\"eval_accuracy\"]\n",
    "        val_loss = metrics[\"eval_loss\"]\n",
    "        self.history[\"val_acc\"].append(val_acc)\n",
    "        self.history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            self.save_model(f\"./saved_model/{model_version}{epoch+1}.0.pt\")\n",
    "            print(f\"Saved best model at epoch {epoch+1} with val_acc={val_acc:.4f}\")\n",
    "\n",
    "    def log_training_epoch(self, train_loss, train_acc):\n",
    "        self.history[\"train_loss\"].append(train_loss)\n",
    "        self.history[\"train_acc\"].append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_dora = torch.optim.AdamW(model.parameters(),lr=1e-5)\n",
    "total_steps = len(train_loader)*EPOCHS\n",
    "\n",
    "scheduler_dora = get_linear_schedule_with_warmup(\n",
    "    optimizer_dora,\n",
    "    num_warmup_steps= 0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b27086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# output dir \n",
    "model_version = \"securityRoBERTa_BaseDoRA_\"\n",
    "model_dir = f\"{model_version}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    run_name=model_version,\n",
    "    output_dir=model_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    num_train_epochs=1,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    logging_dir=f\"{model_dir}/logs\",\n",
    "    fp16=True,  # Enable mixed precision training\n",
    "    dataloader_num_workers=4,  # Adjust based on your CPU capabilities\n",
    "    gradient_checkpointing=True,  # Enable gradient checkpointing to save memory\n",
    "    report_to=\"none\",  # Disable reporting to avoid unnecessary overhead\n",
    "    label_names=[\"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, confusion_matrix\n",
    "# The parameters after appling DoRA\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"macro_f1\": macro_f1}\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61746313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "metrics_callback = MetricsCallback()\n",
    "\n",
    "# New trainer\n",
    "trainer_dora = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=custom_tokenizer,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Train for one epoch (Trainer handles batches internally)\n",
    "    trainer_dora.train()\n",
    "\n",
    "    trainer_dora.log_training_epoch(metrics_callback.epoch_train_losses[-1], metrics_callback.epoch_train_accuracies[-1])\n",
    "\n",
    "    # Evaluate and potentially save best model\n",
    "    trainer_dora.evaluate_and_save(\n",
    "        epoch,\n",
    "        model_version\n",
    "    )\n",
    "\n",
    "history_roberta_base_dora = trainer_dora.history\n",
    "\n",
    "# Save full history and training time\n",
    "end_time = time.time()\n",
    "history_roberta_base_dora[\"training_time\"].append(end_time - start_time)\n",
    "\n",
    "torch.save(history_roberta_base_dora, \"./saved_model/history_roberta_base_dora.pt\")\n",
    "print(\"Training complete and history saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "history_roberta_base_dora = torch.load(\"./saved_model/history_roberta_base_dora.pt\", weights_only=False)\n",
    "\n",
    "# Still a defaultdict with tensors\n",
    "print(type(history_roberta_base_dora))  # defaultdict\n",
    "print(type(history_roberta_base_dora['train_acc'][0]))  # torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33331f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "epochs = range(1, EPOCHS+1)\n",
    "train_losses = history_roberta_base_dora['train_loss']\n",
    "print(train_losses)\n",
    "val_losses = history_roberta_base_dora['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(x=epochs, y=train_losses, label='Training Loss',marker=\"o\")\n",
    "sns.lineplot(x=epochs, y=val_losses, label='Validation Loss',marker=\"o\")\n",
    "\n",
    "plt.title('RoBERTa Base DoRA Training and Validation Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('./roberta-base-dora-training-validation-losses.png',dpi=780)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1febc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, EPOCHS+1)\n",
    "train_accuracies = history_roberta_base_dora['train_acc']\n",
    "val_accuracies = history_roberta_base_dora['val_acc']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(x=epochs, y=train_accuracies, label='Training accuracy',marker='o')\n",
    "sns.lineplot(x=epochs, y=val_accuracies, label='Validation accuracy',marker='o')\n",
    "\n",
    "plt.title('RoBERTa Base DoRA Training and Validation Accuracies')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('./roberta-base-dora-training-validation-accuracies.png',dpi=780)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d803d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import PredictionOutput\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "def get_predictions(trainer, test_dataset):\n",
    "    # Runs prediction\n",
    "    output: PredictionOutput = trainer.predict(test_dataset)\n",
    "\n",
    "    # Get raw logits and labels\n",
    "    logits = torch.tensor(output.predictions)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "    labels = torch.tensor(output.label_ids)\n",
    "\n",
    "    return preds, probs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, probs, labels = get_predictions(trainer_dora, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4510d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(preds,\"./saved_model/roberta_base_dora_predictions.pt\")\n",
    "torch.save(probs,\"./saved_model/roberta_base_dora_predictions_probs.pt\")\n",
    "torch.save(labels,\"./saved_model/roberta_base_dora_real_values.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Backdoor', 'DDoS_HTTP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_UDP',\n",
    "       'Fingerprinting', 'MITM', 'Normal', 'Password', 'Port_Scanning',\n",
    "       'Ransomware', 'SQL_injection', 'Uploading', 'Vulnerability_scanner',\n",
    "       'XSS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in preds:\n",
    "  s.add(elt.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6825de",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_considered_classes = [TARGET_LIST[i] for i in s]\n",
    "actual_considered_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e02f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"RoBERTa Base DoRA Confusion Matrix\")\n",
    "    plt.ylabel('Real threats')\n",
    "    plt.xlabel('Predicted threats')\n",
    "    plt.savefig('./roberta-base-dora-confusion-matrix.png',dpi=780)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d11d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels,preds,target_names=TARGET_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab68a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels,preds)\n",
    "df_cm = pd.DataFrame(cm,index=TARGET_LIST,columns=TARGET_LIST)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0881076",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labels.cpu().numpy()\n",
    "y_score = preds.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
